spring.application.name=intelligent-telegram-bot


#chat
spring.ai.openai.base-url=https://api.groq.com/openai
#spring.ai.openai.chat.options.model=llama3-70b-8192
spring.ai.openai.chat.options.model=llama3-8b-8192
spring.ai.openai.chat.options.temperature=0.1
spring.ai.openai.chat.options.presence-penalty=2
spring.ai.openai.chat.options.frequency-penalty=2
spring.ai.openai.chat.options.max-tokens=8192
spring.ai.ollama.chat.enabled=false
spring.ai.mistralai.chat.enabled=false

#retry
spring.ai.retry.on-client-errors=true
spring.ai.retry.backoff.initial-interval=8


#embedding
spring.ai.openai.embedding.enabled=false
spring.ai.ollama.embedding.enabled=true
spring.ai.ollama.embedding.model=nomic-embed-text
#spring.ai.ollama.embedding.model=mxbai-embed-large
#spring.ai.ollama.embedding.options.num-ctx=8192
#spring.ai.ollama.embedding.options.num-thread=10
#spring.ai.ollama.embedding.options.top-k=10
#spring.ai.ollama.embedding.options.top-p=0.1
#spring.ai.ollama.embedding.options.temperature=0.1
#spring.ai.ollama.embedding.options.num-batch=8192

#vector store
spring.ai.vectorstore.pgvector.initialize-schema=true


#docker compose
spring.docker.compose.lifecycle-management=start_only
spring.docker.compose.enabled=false

#logging
logging.level.org.springframework.ai.chat.client.advisor=trace


#observation
management.endpoints.web.exposure.include=health,info,metrics,prometheus
#management.metrics.distribution.percentiles-histogram.http.server.requests=true
management.endpoint.health.show-details=always