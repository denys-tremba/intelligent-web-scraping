spring.application.name=intelligent-telegram-bot


#chat
spring.ai.openai.base-url=https://api.groq.com/openai
#spring.ai.openai.chat.options.model=llama3-70b-8192
#spring.ai.openai.chat.options.model=llama3-8b-8192
spring.ai.openai.chat.options.model=llama-3.1-70b-versatile
spring.ai.openai.chat.options.temperature=0.1
spring.ai.openai.chat.options.presence-penalty=2
spring.ai.openai.chat.options.frequency-penalty=2
spring.ai.openai.chat.options.max-tokens=8000
spring.ai.ollama.chat.enabled=false
spring.ai.embedding.transformer.enabled=false

#retry
spring.ai.retry.on-client-errors=true
spring.ai.retry.backoff.initial-interval=8


spring.ai.embedding.transformer.onnx.modelUri=https://huggingface.co/intfloat/e5-small-v2/resolve/main/model.onnx
spring.ai.embedding.transformer.tokenizer.uri=https://huggingface.co/intfloat/e5-small-v2/raw/main/tokenizer.json

#embedding
spring.ai.openai.embedding.enabled=false
spring.ai.ollama.embedding.enabled=true
spring.ai.ollama.embedding.model=nomic-embed-text
#spring.ai.ollama.embedding.model=mxbai-embed-large
#spring.ai.ollama.embedding.options.num-ctx=8192
#spring.ai.ollama.embedding.options.num-thread=10
#spring.ai.ollama.embedding.options.top-k=10
#spring.ai.ollama.embedding.options.top-p=0.1
#spring.ai.ollama.embedding.options.temperature=0.1
#spring.ai.ollama.embedding.options.num-batch=8192

#vector store
spring.ai.vectorstore.cassandra.initialize-schema=true

#docker compose
spring.docker.compose.lifecycle-management=start_only


#observation
management.endpoints.web.exposure.include=health, info, metrics, prometheus
management.metrics.distribution.percentiles-histogram.http.server.requests=true
management.observations.key-values.application=intelligent-web-scrapper-observability

management.tracing.sampling.probability=1.0
management.zipkin.tracing.endpoint=http://localhost:9411/api/v2/spans

## percentiles histogram
management.metrics.distribution.percentiles-histogram.gen_ai.client.operation=true
management.metrics.distribution.percentiles-histogram.db.vector.client.operation=true
management.metrics.distribution.percentiles-histogram.spring.ai.chat.client=true

## Context propagation for Reactor
spring.reactor.context-propagation=auto

######################################
# Spring AI observability settings
######################################

## Include the Chatclient input in observations
spring.ai.chat.client.observations.include-input=true

## Include the VectorStor query and response in observations
spring.ai.vectorstore.observations.include-query-response=true
## Include prompt and completion contents in observations
spring.ai.chat.observations.include-prompt=true
spring.ai.chat.observations.include-completion=true

## Include error logging in observations (note: not needed for Spring Web apps)
spring.ai.chat.observations.include-error-logging=true

######################################
# Logging
######################################

## Disable logs
logging.level.com.zaxxer.hikari=ERROR
logging.level.org.springframework.ai=ERROR
logging.level.org.apache.fontbox.ttf=ERROR
logging.level.org.apache.pdfbox.pdmodel.font=OFF
